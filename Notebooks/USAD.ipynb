{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "etniX_KTlJ5U"
   },
   "source": [
    "# USAD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N3jM0qLU8MgZ"
   },
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /nfs/home/medoro/Unsupervised_Anomaly_Detection_thesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6u1DGKsAlLF-"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from USAD.utils import *\n",
    "from USAD.usad import *\n",
    "#from linear_ae import *\n",
    "#from utils_ae import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "4AzWlDBI_djV",
    "outputId": "7a8d0c19-2389-461b-c0be-3427a25dda91"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi -L\n",
    "\n",
    "device = get_default_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1crx5rGP9ONf"
   },
   "source": [
    "## EDA - Data Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kfSj4FYL9W8Y"
   },
   "source": [
    "### Normal period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read data\n",
    "normal = pd.read_csv(\"data/SWaT_Dataset_Normal_v1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal['Timestamp'] = pd.to_datetime(normal['Timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_sorted = normal['Timestamp'].is_monotonic_increasing\n",
    "print(f\"Dataset sorted by timestamp: {is_sorted}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "id": "XeDLxV_r1G9n",
    "outputId": "576538dd-64f2-46fa-8e6f-6c2ffdebad15"
   },
   "outputs": [],
   "source": [
    "normal = normal.drop([\"Timestamp\" , \"Normal/Attack\" ] , axis = 1)\n",
    "normal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fFuLm1GH1G2n"
   },
   "outputs": [],
   "source": [
    "# Transform all columns into float64\n",
    "for i in list(normal): \n",
    "    normal[i]=normal[i].apply(lambda x: str(x).replace(\",\" , \".\"))\n",
    "normal = normal.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zxFNH5kU9hIE"
   },
   "source": [
    "#### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mfxj4Uxn9kv4"
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "x = normal.values\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "normal = pd.DataFrame(x_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 126
    },
    "id": "mQ6_U4jn9nlw",
    "outputId": "f1cc1bd6-f1cc-4764-b1cc-2fd989ac4918"
   },
   "outputs": [],
   "source": [
    "normal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_i71RFAi9spa"
   },
   "source": [
    "### Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "id": "aN_TFp5x9uTE",
    "outputId": "38d7993d-c9a3-461d-c430-ebde697afbc6"
   },
   "outputs": [],
   "source": [
    "#Read data\n",
    "attack = pd.read_csv(\"data/SWaT_Dataset_Attack_v0.csv\",sep=\";\")\n",
    "labels = [ float(label!= 'Normal' ) for label  in attack[\"Normal/Attack\"].values]\n",
    "attack = attack.drop([\"Timestamp\" , \"Normal/Attack\" ] , axis = 1)\n",
    "attack.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qLCInT-I9_-D"
   },
   "outputs": [],
   "source": [
    "# Transform all columns into float64\n",
    "for i in list(attack):\n",
    "    attack[i]=attack[i].apply(lambda x: str(x).replace(\",\" , \".\"))\n",
    "attack = attack.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c4cB4v3N-Dhu"
   },
   "source": [
    "#### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jZrha9cO-BGK"
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "x = attack.values \n",
    "x_scaled = min_max_scaler.transform(x)\n",
    "attack = pd.DataFrame(x_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 126
    },
    "id": "z9SwiPco-BUa",
    "outputId": "f2507282-c0f9-4253-ece7-0a802b68240f"
   },
   "outputs": [],
   "source": [
    "attack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xXJi503b-j_d"
   },
   "source": [
    "### Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vyplttZa-BRN"
   },
   "outputs": [],
   "source": [
    "window_size=12 #9 ---> for better reconstruction #12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "dzGJMp6Y-BN5",
    "outputId": "2949d278-1313-442c-f06b-275a8c6c6578"
   },
   "outputs": [],
   "source": [
    "windows_normal=normal.values[np.arange(window_size)[None, :] + np.arange(normal.shape[0]-window_size)[:, None]]\n",
    "windows_normal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "17LdB3c8-pRH",
    "outputId": "721059d4-5937-4dd3-d73c-e5d255fc273c"
   },
   "outputs": [],
   "source": [
    "windows_attack=attack.values[np.arange(window_size)[None, :] + np.arange(attack.shape[0]-window_size)[:, None]]\n",
    "windows_attack.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k70ZFxGs-_7m"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yi9S0SGnDKNc"
   },
   "outputs": [],
   "source": [
    "import torch.utils.data as data_utils\n",
    "\n",
    "BATCH_SIZE =  7919\n",
    "N_EPOCHS = 100\n",
    "hidden_size = 40\n",
    "\n",
    "w_size=windows_normal.shape[1]*windows_normal.shape[2] #12*51 = 612\n",
    "z_size=windows_normal.shape[1]*hidden_size # 12*100 = 1200\n",
    "\n",
    "#ENCODER:\n",
    "#612 --> 306\n",
    "#306 --> 153\n",
    "#153 --> 1200\n",
    "\n",
    "windows_normal_train = windows_normal[:int(np.floor(.8 *  windows_normal.shape[0]))]\n",
    "windows_normal_val = windows_normal[int(np.floor(.8 *  windows_normal.shape[0])):int(np.floor(windows_normal.shape[0]))]\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(data_utils.TensorDataset(\n",
    "    torch.from_numpy(windows_normal_train).float().view(([windows_normal_train.shape[0],w_size]))\n",
    ") , batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(data_utils.TensorDataset(\n",
    "    torch.from_numpy(windows_normal_val).float().view(([windows_normal_val.shape[0],w_size]))\n",
    ") , batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(data_utils.TensorDataset(\n",
    "    torch.from_numpy(windows_attack).float().view(([windows_attack.shape[0],w_size]))\n",
    ") , batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "model = UsadModel(w_size, z_size)\n",
    "model = to_device(model,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "So9yjDPEDObC",
    "outputId": "629bcd13-37b1-4907-ef0d-46d9e3ad5398",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = training(N_EPOCHS,model,train_loader,val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "fYwlN0JKVVtN",
    "outputId": "c742ff8b-3b4a-41f5-dd09-effee1be928a"
   },
   "outputs": [],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ieObNqKYsOzh"
   },
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'encoder': model.encoder.state_dict(),\n",
    "            'decoder1': model.decoder1.state_dict(),\n",
    "            'decoder2': model.decoder2.state_dict()\n",
    "            }, \"checkpoints/usad_model2.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ymhjbmvR_DgJ"
   },
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "b7rbm9wdXKeF",
    "outputId": "076309c7-22be-41f6-f916-5f11cb679672"
   },
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"checkpoints/usad_model.pth\", map_location = torch.device('cpu')) #usad_model.pth con window = 12; usad_model2.pth con window = 9\n",
    "\n",
    "model.encoder.load_state_dict(checkpoint['encoder'])\n",
    "model.decoder1.load_state_dict(checkpoint['decoder1'])\n",
    "model.decoder2.load_state_dict(checkpoint['decoder2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ry1QTp6V2ny4"
   },
   "outputs": [],
   "source": [
    "results=testing(model,test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Qui va ad ottenere le label per ogni finestra\n",
    "# Input modello Ã¨ una lista di array, ognuno corrispondente a una sliding window con stride = 1 sui dati originali\n",
    "# Quindi dobbiamo applicare la sliding window anche sulle label\n",
    "windows_labels=[]\n",
    "for i in range(len(labels)-window_size):\n",
    "    windows_labels.append(list(np.int_(labels[i:i+window_size])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "windows_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = [1.0 if (np.sum(window) > 0) else 0 for window in windows_labels ]\n",
    "# Qui vado a dare le label 1 per ogni finestra: se tutta la finestra contiene label = 0, allora y_test(t) = 0, altrimenti = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FSWwxheNvxR7"
   },
   "outputs": [],
   "source": [
    "y_pred=np.concatenate([torch.stack(results[:-1]).flatten().detach().cpu().numpy(),\n",
    "                              results[-1].flatten().detach().cpu().numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "bROUyLM93cG3",
    "outputId": "755359d9-d0fb-4deb-b313-d3c2a2465a26"
   },
   "outputs": [],
   "source": [
    "threshold=ROC(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_ = np.zeros(y_pred.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_[y_pred >= threshold] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.metrics.roc_auc_score(y_test, y_pred_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(np.array(y_test), y_pred_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sklearn.metrics.classification_report(y_test, y_pred_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred.min(), y_pred.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = np.percentile(y_pred, 93)\n",
    "print(threshold)\n",
    "y_pred_ = np.zeros(y_pred.shape[0])\n",
    "y_pred_[y_pred >= threshold] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_pred_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_.sum()/len(y_pred_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(np.array(y_test), y_pred_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sklearn.metrics.classification_report(y_test, y_pred_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.metrics.roc_auc_score(y_test, y_pred_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack.loc[:449906, 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "att = attack.loc[:449906, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "att"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "att['y_gt'] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "att['y_pred'] = y_pred_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_an = att[att.y_gt == 1]\n",
    "pred_an = att[att.y_pred == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_an.shape, pred_an.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(att.index, att.loc[:, 0], label = \"first_feature\", color = \"blue\")\n",
    "plt.scatter(true_an.index, true_an.y_gt, label = \"true anomaly\", color = \"red\")\n",
    "plt.scatter(pred_an.index, pred_an.y_pred, label = \"predicted anomaly\", color = \"green\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=attack.index, y=attack.loc[:, 0], name='First feature'))\n",
    "fig.add_trace(go.Scatter(x=attack.index, y=y_test, mode='markers', marker=dict(color='forestgreen'), name='True_Anomaly'))\n",
    "fig.add_trace(go.Scatter(x=attack.index, y=y_pred_, mode='markers', marker=dict(color='yellow'), name='W1_anomaly'))\n",
    "\n",
    "fig.update_layout(showlegend=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconstruction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to see what the actual reconstruction looks like (for this window = 9 is better)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to firstly create non overlapping windows from the attack dataset, then we pass them to the model and take the corresponding result, to then perform anomaly detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def windows_non_overlapping(dataframe, window_size):\n",
    "  total_length = dataframe.shape[0]\n",
    "  output = []\n",
    "  data = np.array(dataframe)\n",
    "  for i in range(0, total_length - window_size + 1, window_size):\n",
    "    # find the end of this sequence\n",
    "    end_ix = i + window_size\n",
    "    # check if we are beyond the dataset length for this building\n",
    "    #if end_ix > total_length-1:\n",
    "     # break\n",
    "    output.append(data[i : (i + window_size),:])\n",
    "  return np.stack(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_wndw = windows_non_overlapping(attack, window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_wndw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_wndw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(data_utils.TensorDataset(\n",
    "    torch.from_numpy(attack_wndw).float().contiguous().view(([attack_wndw.shape[0],w_size]))\n",
    ") , batch_size=BATCH_SIZE, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_non_over, w1_non_over = testing_prova(model, test_loader) #, w2_non_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_non_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_non_over[0].size(), results_non_over[-1].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1_non_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#w2_non_over"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## w1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(w1_non_over), w1_non_over[0].size(), w1_non_over[-1].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fai reshape da [batch, 459] a [batch, 9, 51]\n",
    "reshaped_w1 = [torch.reshape(w1_el, (w1_el.size()[0], int(w1_el.size()[1]/51), int(w1_el.size()[1]/12))) for w1_el in w1_non_over]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped_w1[0].size(), reshaped_w1[-1].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped_w1_try = [torch.reshape(w1_el, (w1_el.size()[0]*w1_el.size()[1], w1_el.size()[2])) for w1_el in reshaped_w1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped_w1_try[0].size(), reshaped_w1_try[-1].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked = torch.stack(reshaped_w1_try[:-1])\n",
    "stacked.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_reshaped = torch.reshape(stacked, (stacked.size()[0] * stacked.size()[1], stacked.size()[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_reshaped.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_array = stacked_reshaped.cpu().numpy()\n",
    "stacked_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_array = reshaped_w1_try[-1].cpu().numpy()\n",
    "last_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = np.concatenate([stacked_array, last_array])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fai reshape da [batch, 459] a [batch, 9, 51]\n",
    "reshaped_w2 = [torch.reshape(w2_el, (w2_el.size()[0], int(w2_el.size()[1]/51), int(w2_el.size()[1]/9))) for w2_el in w2_non_over]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped_w2[0].size(), reshaped_w2[-1].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped_w2_try = [torch.reshape(w2_el, (w2_el.size()[0]*w2_el.size()[1], w2_el.size()[2])) for w2_el in reshaped_w2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped_w2_try[0].size(), reshaped_w2_try[-1].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked2 = torch.stack(reshaped_w2_try[:-1])\n",
    "stacked2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_reshaped2 = torch.reshape(stacked2, (stacked2.size()[0] * stacked2.size()[1], stacked2.size()[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_reshaped2.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_array = stacked_reshaped2.cpu().numpy()\n",
    "stacked_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_array2 = reshaped_w2_try[-1].cpu().numpy()\n",
    "last_array2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total2 = np.concatenate([stacked_array, last_array2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstruction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have reconstructed, let's try to see how it maps the different time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_w1_reco = pd.DataFrame(total)\n",
    "attack_w1_reco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_w2_reco = pd.DataFrame(total2)\n",
    "attack_w2_reco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_w2_reco.loc[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(len(attack.loc[:, 0])), attack.loc[:, 0], label = \"First feature\") #predicted_df_test.meter_reading[:8784]\n",
    "plt.plot(np.arange(len(attack_w1_reco.loc[:, 0])), attack_w1_reco.loc[:, 0], label = \"w1_reconstruction\")\n",
    "#plt.plot(np.arange(len(attack_w2_reco.loc[:, 0])), attack_w2_reco.loc[:, 0], label = \"w2_reconstruction\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(labels, marker = 'o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(attack.loc[:, 0], label = \"First feature\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try my anomaly detection method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'attack_gt': attack.loc[:449915, 0].values, 'attack_w1_reco': attack_w1_reco.loc[:, 0].values} #, 'attack_w2_reco': attack_w2_reco.loc[:, 0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack.loc[:449915, 0].values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_w1_reco.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_df_test = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_df_test['loss'] = np.abs(predicted_df_test['attack_gt'] - predicted_df_test['attack_w1_reco'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_df_test['loss2'] = np.abs(predicted_df_test['attack_gt'] - predicted_df_test['attack_w2_reco'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_df_test['relative_loss'] = np.abs((predicted_df_test['attack_w1_reco']-predicted_df_test['attack_gt'])/predicted_df_test['attack_w1_reco'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_df_test['relative_loss2'] = np.abs((predicted_df_test['attack_w2_reco']-predicted_df_test['attack_gt'])/predicted_df_test['attack_w2_reco'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate threshold on relative loss quartiles but only on test\n",
    "test_loss = predicted_df_test.relative_loss.values\n",
    "threshold = np.percentile(test_loss, 67)\n",
    "predicted_df_test['threshold']= threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate threshold on absolute loss quartiles but only on val, and in this case per \n",
    "test_loss = predicted_df_test.loss.values\n",
    "threshold = np.percentile(test_loss, 90)\n",
    "predicted_df_test['threshold']= threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss = predicted_df_test.relative_loss2.values\n",
    "threshold = np.percentile(val_loss, 67)\n",
    "#(np.percentile(val_loss, 75)) + 1.5 *((np.percentile(val_loss, 75))-(np.percentile(val_loss, 25)))\n",
    "predicted_df_test['threshold2']= threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate threshold on absolute loss quartiles but only on val, and in this case per \n",
    "test_loss = predicted_df_test.loss2.values\n",
    "threshold = np.percentile(test_loss, 67)\n",
    "predicted_df_test['threshold2']= threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_df_test['predicted_anomaly'] = predicted_df_test['loss'] > predicted_df_test['threshold'] #relative_loss\n",
    "predicted_df_test['predicted_anomaly']=predicted_df_test['predicted_anomaly'].replace(False,0)\n",
    "predicted_df_test['predicted_anomaly']=predicted_df_test['predicted_anomaly'].replace(True,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_df_test['predicted_anomaly2'] = predicted_df_test['loss2'] > predicted_df_test['threshold2'] #relative_loss2\n",
    "predicted_df_test['predicted_anomaly2']=predicted_df_test['predicted_anomaly2'].replace(False,0)\n",
    "predicted_df_test['predicted_anomaly2']=predicted_df_test['predicted_anomaly2'].replace(True,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_df_test.predicted_anomaly.sum() / len(predicted_df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_df_test.predicted_anomaly2.sum() / len(predicted_df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(labels[:-3], predicted_df_test['predicted_anomaly']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(labels, predicted_df_test['predicted_anomaly2']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(labels[:-3], predicted_df_test['predicted_anomaly'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(labels, predicted_df_test['predicted_anomaly2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_df_test['anomaly'] = labels[:-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_anomalies = predicted_df_test.loc[predicted_df_test['predicted_anomaly'] == 1]\n",
    "#predicted_anomalies2 = predicted_df_test.loc[predicted_df_test['predicted_anomaly2'] == 1]\n",
    "true_anomalies = predicted_df_test.loc[predicted_df_test['anomaly'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=predicted_df_test.index, y=predicted_df_test.attack_gt, name='First feature'))\n",
    "fig.add_trace(go.Scatter(x=predicted_df_test.index, y=predicted_df_test.attack_w1_reco, name='w1 reconstruction'))\n",
    "#fig.add_trace(go.Scatter(x=predicted_df_test.index, y=predicted_df_test.attack_w2_reco, name='w2 reconstruction'))\n",
    "fig.add_trace(go.Scatter(x=true_anomalies.index, y=true_anomalies.anomaly, mode='markers', marker=dict(color='forestgreen'), name='True_Anomaly'))\n",
    "fig.add_trace(go.Scatter(x=predicted_anomalies.index, y=predicted_anomalies.predicted_anomaly, mode='markers', marker=dict(color='yellow'), name='W1_anomaly'))\n",
    "#fig.add_trace(go.Scatter(x=predicted_anomalies2.index, y=predicted_anomalies2.anomaly, mode='markers', marker=dict(color='orange'), name='W2_Anomaly'))\n",
    "fig.update_layout(showlegend=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12, 6))\n",
    "plt.plot(np.arange(len(predicted_df_test)), predicted_df_test.attack_gt, label = \"First feature\")\n",
    "plt.plot(np.arange(len(predicted_df_test)), predicted_df_test.attack_w1_reco, label = \"w1_reconstruction\")\n",
    "#plt.plot(np.arange(len(predicted_df_test)), predicted_df_test.attack_w2_reco, label = \"w2_reconstruction\")\n",
    "#plt.plot(np.arange(len(true_anomalies)), true_anomalies.anomaly)\n",
    "plt.scatter(true_anomalies.index,true_anomalies.anomaly, color = \"red\", label = \"anomalies\" )\n",
    "plt.scatter(predicted_anomalies.index,predicted_anomalies.predicted_anomaly, color = \"green\", label = \"Predicted anomalies\" )\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "USAD_test.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
